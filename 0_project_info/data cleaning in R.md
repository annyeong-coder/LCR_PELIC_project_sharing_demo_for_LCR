source:  https://towardsdatascience.com/data-cleaning-in-r-made-simple-1b77303b0b17

# towards data science
source: https://towardsdatascience.com/data-cleaning-in-r-made-simple-1b77303b0b17



## Step 3: Check for data irregularities

Next, we’ll evaluate the dataset for irregularities, which consist of accuracy concerns like **invalid values** and **outliers**. Again, these are two common pitfalls in messy data frames, but be aware of irregularities specific to your own data.

**a) Invalid values**: These are responses that don’t make logical sense. For example, the first question in our dataset (“Are you self-employed?”) should align with the second (“How many employees does your company or organization have?”). If there is a “1” in the first column indicating that the individual is self-employed, there should be an “NA” in the second column as he or she doesn’t work for a company.

![](https://miro.medium.com/max/524/1*RkcH-RfYwKYPEdj3V4FZCg.png)

Another common example is age. Our dataset consists of responses from tech employees, meaning anyone reporting an age older than 80 or younger than 15 is likely to be an entry error. Let’s take a look:

![](https://miro.medium.com/max/700/1*9iqWsYpke04ubr72FsWH_A.png)

It is safe to say that a 3-yr-old and 323-yr-old did not complete an employee survey. To remove the invalid entries, we can use the following code:

df <- df[-c(which(df$age > 80 | df$age < 15)), ]

![](https://miro.medium.com/max/700/1*FeOQrQCYcGLIMYujTNz9Xg.png)

**b) Outliers**: This is a topic with much debate. Check out the [Wikipedia](https://en.wikipedia.org/wiki/Outlier) article for an in-depth overview of what can constitute an outlier.

After a little feature engineering (check out the full data cleaning script [here](https://github.com/emiburns/mental-health-in-tech-medium-project) for reference), our dataset has 3 continuous variables: _age_, _the number of diagnosed mental illnesses each respondent has_, and _the number of believed mental illnesses each respondent has_. To get a feeling for how the data is distributed, we can plot histograms for each variable:

![](https://miro.medium.com/max/700/1*-GUKGBawARTt2BTe5AUMaQ.png)

Both “total_dx” and “total_dx_belief” are heavily skewed. If we wanted to mitigate the impact of extreme outliers, there are 3 common ways to do so: _delete the outlier_, _replace the value_ (aka W_insorize_), or _do nothing_.

**Delete the observation**: Locate and remove the observation with the extreme value. This is common when dealing with extreme values that are clearly the result of human entry error (like the 323-year value previously entered in our “age” column). However, be careful when this is not the case as deleting observations can lead to a loss of important information.

**Winsorize**: When an outlier is negatively impacting your model assumptions or results, you may want to replace it with a less extreme maximum value. In Winsorizing, values outside a predetermined percentile of the data are identified and set to said percentile. The following is an example of 95% Winsorization with our dataset:

#looking at number of values above 95th percentile   
sum(df$total_dx > quantile(df$total_dx, .95))df <- df %>% mutate(wins_total_dx = Winsorize(total_dx))

**Do nothing**: Yep, just… do nothing. This is the best approach if the outliers, although extreme, hold important information relevant to your project aims. This is the approach we’ll take with our “total_dx” variable as the number of reported mental illnesses for each respondent has the potential to be an important predictor of tech employees’ attitudes towards mental health.

**An additional note**: It may be the era of big data, but small sample sizes are still a stark reality for those within clinical fields, myself included. If this is also your reality, take extra care with outliers as their effect on the sample mean, standard deviation, and variance increases as sample size decreases.

## Step 4: Decide how to deal with missing values

I’ll cut straight to the chase here: _There is no single “best” way to deal with missing values in a data set_.

![](https://miro.medium.com/max/700/0*I3Ds6RDoP3VrYU85)

Photo by [krakenimages](https://unsplash.com/@krakenimages?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

This can sound daunting, but understanding your data and domain subject (_recall Step 1?_) can come in handy. If you know your data well, chances are you’ll have a decent idea of what method will best apply to your specific scenario too.

Most of our dataset’s NA values are due to dependent responses (i.e. if you respond with “Yes” to one question, you can skip the following), rather than human error. This variance is widely explained by the diverging response patterns generated by self-employed and company-employed directed questions. After splitting the dataset into two frames (one for company-employed respondees and one for self-employed respondees), we calculate the total missing values for the company-employed specific dataset:

sum(is.na(df))#percent missing values per variable  
apply(df, 2, function(col)sum(is.na(col))/length(col))

![](https://miro.medium.com/max/700/1*uyf50mE-W-AoPFV2f5k_hA.png)

It may look like a lot of missing values, but, upon further inspection, the only columns with missing values are those directed at self-employed respondees (for instance, “Do you have medical coverage (private insurance or state-provided) which includes treatment of mental health issues?”). Missing values in this variable should be expected in our company-employed dataset as they are instead covered by company policy.

Which leads us to the first option:

**a) Remove the variable**. Delete the column with the NA value(s). In projects with large amounts of data and few missing values, this may be a valid approach. It is also acceptable in our case, where the self-employed variables add no significant information to our company-employed dataset.

However, if you’re dealing with a smaller dataset and/or a multitude of NA values, keep in mind removing variables can result in a significant loss of information.

**b) Remove the observation**. Delete the row with the NA value. Again, this may be an acceptable approach in large projects but beware of the potential loss of valuable information. To remove observations with missing values, we can easily employ the dplyr library again:

#identifying the rows with NAs  
rownames(df)[apply(df, 2, anyNA)]#removing all observations with NAs  
df_clean <- df %>% na.omit()

**c) Impute the missing value**. Substitute NA values with inferred replacement values. We can do so using the mean, median, or mode of a given variable like so:

for(i in 1:ncol(df)){  
  df[is.na(df[,i]), i] <- mean(df[,i], na.rm = TRUE)  
}

We can additionally impute continuous values using predictive methods such as **linear regression**, or impute categorical values using methods like **logistic regression** or **ANOVA**. [**Multiple imputation**](https://data.library.virginia.edu/getting-started-with-multiple-imputation-in-r/) with libraries such as [MICE](https://cran.r-project.org/web/packages/mice/index.html) can also be used with either continuous or categorical data. When implementing these methods, be aware that the results can be misleading if there is no relationship between the missing value and dataset attributes. You can learn more about these techniques and their related R packages [here](https://www.kdnuggets.com/2017/09/missing-data-imputation-using-r.html).

[KNN imputation](https://www.rdocumentation.org/packages/impute/versions/1.46.0/topics/impute.knn) offers yet another probable alternative to imputing either continuous or categorical missing values, but keep in mind it can be time-consuming and highly dependent on the chosen k-value.

#imputing missing values with the caret package's knn method  
df_preprocess <- preProcess(df %>% dplyr::select(primary_role),  
                            method = c("knnImpute"),  
                            k = 10,  
                            knnSummary = mean)df_impute <- predict(df_preprocess, df, na.action = na.pass)

**d) Use algorithms that support missing values**. Some algorithms will break if used with NA values, others won’t. If you want to keep the NA’s in your dataset, consider using algorithms that can process missing values such as linear regression, k-Nearest Neighbors, or XGBoost. This decision will also strongly depend on long-term project aims.

## Step 5: Document data versions and changes made

Let’s say it loud and clear for the folks in the back: **Good research is reproducible research**. If you or a third party cannot reproduce the _same clean dataset_ from the _same raw dataset_ you used, you (or anyone else) cannot validate your findings.

Clear documentation is a crucial facet of good data cleaning. _Why did you make the changes that you did? How did you do them? What version of the raw data did you use?_ These are all important questions you need to be able to answer. Tools like [R Markdown](https://rmarkdown.rstudio.com/) and [RPubs](https://rpubs.com/) can seamlessly weave documentation into your R project. Check them out if you’re not already familiar. Your future self will thank you.


# geeksforgeeks
source:  https://www.geeksforgeeks.org/data-cleaning-in-r/

## **Data Cleaning in R**

Data Cleaning is the process to transform raw data into consistent data that can be easily analyzed. It is aimed at filtering the content of statistical statements based on the data as well as their reliability. Moreover, it influences the statistical statements based on the data and improves your data quality and overall productivity.

## Purpose of Data Cleaning

The following are the various purposes of data cleaning:

-   Eliminate Errors
-   Eliminate Redundancy
-   Increase Data Reliability
-   Delivery Accuracy
-   Ensure Consistency
-   Assure Completeness
-   Standardize your approach

## **Overview of a typical data analysis chain**

This section represents an overview of a typical data analysis. Each rectangle in the figure represents data in a certain state while each arrow represents the activities needed to get from one state to the other. The first state (**Raw data**) is the data as it comes in. Raw data may lack headers, contain wrong data types, wrong category labels, unknown or unexpected character encoding, and so on. Once this preprocessing has taken place, data can be deemed **Technically correct Data**. That is, in this state data can be read into an R data.frame, with correct names, types, and labels, without further trouble. However, this does not mean that the values are error-free or complete. **Consistent data** is the stage where data is ready for statistical inference. It is the data that most statistical theories use as a starting point. 

![](https://media.geeksforgeeks.org/wp-content/uploads/20220603131009/Group42.jpg)

## **How to clean data in R**

Here, this involves various steps, as from the initial raw data have to move toward the consistent and highly efficient data which is ready to me implement as per the requirements and produces the highly precise and accurate statistical results. The steps vary from data to data as in this case the user should be aware of the date he/she is using for the results. As there are many characteristics and common symptoms of messy data which totally depend on the data used by the user for analysis.

**Characteristics of clean data include data are:**

-     Free of duplicate rows/values
-     Error-free (misspellings free )
-     Relevant (special characters free )
-     The appropriate data type for analysis
-     Free of outliers (or only contain outliers that have been identified/understood)
-     Follows a “[tidy data](https://www.geeksforgeeks.org/processing-of-raw-data-to-tidy-data-in-r/)” structure

**Common symptoms of messy data:**

-     Special characters (e.g. commas in numeric values)
-     Numeric values stored as text/character data types
-     Duplicate rows
-     Misspellings
-     Inaccuracies
-     White space
-     Missing data
-     Zeros instead of null values vary.

## Let’s Start the implementation of Data Cleaning in R

For this, we will use inbuilt datasets(air quality datasets) which are available in R. 

`head``(airquality)`

**Output:**

![](https://media.geeksforgeeks.org/wp-content/uploads/20220602182416/Screenshotfrom20220602182400.png)

In the above dataset, we can clearly see the NA value inside the columns which will generate the error or not produce the accurate predictions for Machine Learning Model.

## Handling missing value in R

To handle the missing value we will check the columns of the datasets, if we found some missing data inside the columns then this generates the NA values as an output, which can be not good for every model. So let’s check it using [mean()](https://www.geeksforgeeks.org/calculate-arithmetic-mean-in-r-programming-mean-function/) methods.


# statistics globe
Source: https://statisticsglobe.com/data-cleaning-r

# Data Cleaning in R (9 Examples)

In this [R](https://statisticsglobe.com/r-programming-language/) tutorial you’ll learn how to perform different [data cleaning](https://www.tableau.com/learn/articles/what-is-data-cleaning) (also called data cleansing) techniques.

The tutorial will contain **nine reproducible examples**. To be more precise, the content is structured as follows:

[1) Creation of Example Data](https://statisticsglobe.com/data-cleaning-r#creation-of-example-data)

[2) Example 1: Modify Column Names](https://statisticsglobe.com/data-cleaning-r#example-1-modify-column-names)

[3) Example 2: Format Missing Values](https://statisticsglobe.com/data-cleaning-r#example-2-format-missing-values)

[4) Example 3: Remove Empty Rows & Columns](https://statisticsglobe.com/data-cleaning-r#example-3-remove-empty-rows-columns)

[5) Example 4: Remove Rows with Missing Values](https://statisticsglobe.com/data-cleaning-r#example-4-remove-rows-with-missing-values)

[6) Example 5: Remove Duplicates](https://statisticsglobe.com/data-cleaning-r#example-5-remove-duplicates)

[7) Example 6: Modify Classes of Columns](https://statisticsglobe.com/data-cleaning-r#example-6-modify-classes-of-columns)

[8) Example 7: Detect & Remove Outliers](https://statisticsglobe.com/data-cleaning-r#example-7-detect-remove-outliers)

[9) Example 8: Remove Spaces in Character Strings](https://statisticsglobe.com/data-cleaning-r#example-8-remove-spaces-in-character-strings)

[10) Example 9: Combine Categories](https://statisticsglobe.com/data-cleaning-r#example-9-combine-categories)

[11) Video & Further Resources](https://statisticsglobe.com/data-cleaning-r#video-further-resources)

Let’s do this…

## Creation of Example Data

We use the following data as a basis for this R programming tutorial:

data <- data.frame(x1 = c(1:4, 99999, 1, NA, 1, 1, NA),   # Create example data frame
                   x1 = c(1:5, 1, "NA", 1, 1, "NA"),
                   x1 = c(letters[c(1:3)], "x  x",  "x", "   y    y y", "x", "a", "a", NA),
                   x4 = "",
                   x5 = NA)
data                                                      # Print example data frame

![table 1 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-1-data-frame-data-cleaning-r-programming-language.png "Table 1")

Have a look at the previous table. It visualizes that our exemplifying data is constituted of ten rows and five variables.

As you might already have noticed, some parts of this data set are not formatted properly. In the following examples, I’ll show some tricks on how to edit and improve the structure of this data set.

Let’s dive right into the examples!

## Example 1: Modify Column Names

Example 1 explains how to clean the column names of a data frame.

Let’s first have a closer look at the names of our data frame columns:

colnames(data)                                            # Print column names
# [1] "x1"   "x1.1" "x1.2" "x4"   "x5"

Let’s assume that we want to change these column names to a consecutive range with the prefix “col”. Then, we can apply the [colnames](https://statisticsglobe.com/rename-column-name-in-r-data-frame/), [paste0](https://statisticsglobe.com/r-paste-paste0-function-example), and [ncol](https://statisticsglobe.com/ncol-r-function/) functions as shown below:

colnames(data) <- paste0("col", 1:ncol(data))             # Modify all column names
data                                                      # Print updated data frame

![table 2 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-2-data-frame-data-cleaning-r-programming-language.png "Table 2")

As shown in Table 2, the previous syntax has created an updated version of our data frame where the column names have been changed.

## Example 2: Format Missing Values

A typical problem for each data preparation and cleaning task are [missing values](https://statisticsglobe.com/missing-data/).

In the R programming language, missing values are usually [represented by NA](https://statisticsglobe.com/r-na/). For that reason, it is useful to convert all missing values to this NA format.

In our specific example data frame, we have the problem that some missing values are represented by blank character strings.

We can print all those blanks to the RStudio console as shown below:

```
data[data == ""]                                          # Print blank data cells
#  [1] NA NA NA "" "" "" "" "" "" "" "" "" "" NA NA NA NA NA NA NA NA NA NA
```

If we want to [assign NA values to those blank cells](https://statisticsglobe.com/replace-blank-by-na-in-r), we can use the following syntax:

```
data[data == ""] <- NA                                    # Replace blanks by NA
```

Another typical problem with missing values – that also occurs in our data set – is that NA values are formatted as the character string “NA”.

Let’s have a closer look at the column col2:

```
data$col2                                                 # Print column
#  [1] "1"  "2"  "3"  "4"  "5"  "1"  "NA" "1"  "1"  "NA"
```

As you can see in the previous output, the NA values in this column are shown between quotes (i.e. “NA”). This indicates that those NA values are formatted as characters instead of real NA values.

We can change that using the following R code:

```
data$col2[data$col2 == "NA"] <- NA                        # Replace character "NA"
```

Let’s have another look at our updated data frame:

```
data                                                      # Print updated data frame
```

![table 3 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-3-data-frame-data-cleaning-r-programming-language.png "Table 3")

In Table 3 it is shown that we have converted all empty characters “” and all character “NA” to true missing values.

## Example 3: Remove Empty Rows & Columns

Example 3 demonstrates how to identify and delete rows and columns that contain only missing values.

On a side note: Example 2 was also important for this step, since the false formatted NA values would not have been recognized by the following R code.

The syntax below demonstrates how to use the [rowSums](https://statisticsglobe.com/r-colsums-rowsums-colmeans-rowmeans-example), [is.na](https://statisticsglobe.com/r-is-na-function/), and ncol functions to [remove only-NA rows](https://statisticsglobe.com/r-remove-data-frame-rows-with-some-or-all-na):

```
data <- data[rowSums(is.na(data)) != ncol(data), ]        # Drop empty rows
data                                                      # Print updated data frame
```
![table 4 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-4-data-frame-data-cleaning-r-programming-language.png "Table 4")

As shown in Table 4, the previous R syntax has kept only rows with non-NA values.

Similar to that, we can also [exclude columns that contain only NA values](https://statisticsglobe.com/r-remove-all-na-columns-from-data-frame):

```
data <- data[ , colSums(is.na(data)) != nrow(data)]       # Drop empty columns
data                                                      # Print updated data frame
```

![table 5 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-5-data-frame-data-cleaning-r-programming-language.png "Table 5")

By executing the previous R programming syntax, we have created Table 5, i.e. a data frame without empty columns.

## Example 4: Remove Rows with Missing Values

As you can see in the previously shown table, our data still contains some NA values in the 7th row of the data frame.

In this example, I’ll explain how to delete all rows with at least one NA value.

This method is called listwise deletion or complete cases analysis, and it **should be done with care**! [Statistical bias](https://en.wikipedia.org/wiki/Bias_(statistics)) might be introduced to your results, if data is removed without theoretical justification.

However, in case you have decided to remove all rows with one or more NA values, you may use the [na.omit function](https://statisticsglobe.com/na-omit-r-example/) as shown below:

```
data <- na.omit(data)                                     # Delete rows with missing values 
data                                                      # Print updated data frame
```

![table 6 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-6-data-frame-data-cleaning-r-programming-language.png "Table 6")

Table 6 shows the output of the previous R programming code: We have removed all rows with missing values.

## Example 5: Remove Duplicates

In this example, I’ll demonstrate how to keep only unique rows in a data set.

For this task, we can apply the [unique function](https://statisticsglobe.com/unique-function-in-r/) to our data frame as demonstrated in the following R snippet:

```
data <- unique(data)                                      # Exclude duplicates
data                                                      # Print updated data frame
```

![table 7 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-7-data-frame-data-cleaning-r-programming-language.png "Table 7")

Table 7 visualizes the output of the previous R programming code – We have removed the last two rows from our data since they were duplicates to the first row.

## Example 6: Modify Classes of Columns

The [class](https://resbaz.github.io/2014-r-materials/lessons/01-intro_r/data-structures.html) of the columns of a data frame is another critical topic when it comes to data cleaning.

This example explains how to [format each column to the most appropriate data type automatically](https://statisticsglobe.com/change-classes-data-frame-columns-automatically-r).

Let’s first check the current classes of our data frame columns:

```
sapply(data, class)                                       # Print classes of all columns
#        col1        col2        col3 
#   "numeric" "character" "character"
```

The first variable col1 is numeric, and the columns col2 and col3 are characters.

We can now use the [type.convert function](https://statisticsglobe.com/type-convert-r-programming-function) to change the column classes whenever it is appropriate:

```
data <- type.convert(data, as.is = TRUE)
data                                                      # Print updated data frame
```

![table 8 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-8-data-frame-data-cleaning-r-programming-language.png "Table 8")

The output of the previous syntax is shown in Table 8: Visually, there’s no difference.

However, if we print the data types of our columns once again, we can see that the first two columns have been changed to the integer class. The character class was retained for the third column.

```
sapply(data, class)                                       # Print classes of updated columns
#        col1        col2        col3 
#   "integer"   "integer" "character"
```

## Example 7: Detect & Remove Outliers

In Example 7, I’ll demonstrate how to detect and delete outliers.

**Please note:** Outlier deletion is another very controversial topic. Please verify that it is justified to extract the outliers from your data frame. Please have a look at the outlier removal guidelines [here](https://statisticsbyjim.com/basics/remove-outliers/).

However, one method to detect outliers is provided by the boxplot.stats function. The following R code demonstrates how to test for outliers in our data frame column col1:

```
data$col1[data$col1 %in% boxplot.stats(data$col1)$out]    # Identify outliers in column
# [1] 99999
```

The previous output has returned one outlier (i.e. the value 99999). This value is obviously much higher than the other values in this column.

Let’s assume that we have confirmed theoretically that the observation containing this outlier should be removed. Then, we can apply the R code below:

```
data <- data[! data$col1 %in% boxplot.stats(data$col1)$out, ]  # Remove rows with outliers
data                                                      # Print updated data frame
```

![table 9 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-9-data-frame-data-cleaning-r-programming-language.png "Table 9")

After running the previous R programming syntax the data frame without outlier shown in Table 9 has been created.

## Example 8: Remove Spaces in Character Strings

The [manipulation](https://statisticsglobe.com/data-manipulation-r) of character strings is another important aspect of the data cleaning process.

This example demonstrates how to avoid blank spaces in the character strings of a certain variable.

For this task, we can use the [gsub function](https://statisticsglobe.com/sub-gsub-r-function-example) as demonstrated below:

```
data$col3 <- gsub(" ", "", data$col3)           # Delete white space in character strings
data                                            # Print updated data frame
```

![table 10 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-10-data-frame-data-cleaning-r-programming-language.png "Table 10")

Table 10 shows the output of the previous syntax: All blanks in the column col3 have been dropped and only the actual letters have been kept.

## Example 9: Combine Categories

Example 9 shows how to [merge certain categories of a categorical variable](https://statisticsglobe.com/group-factor-levels-in-r).

The following R code illustrates how to group the categories “a”, “b”, and “c” in a single category “a”.

Consider the R syntax below:

```
data$col3[data$col3 %in% c("b", "c")] <- "a"              # Merge categories
data                                                      # Print updated data frame
```

![table 11 data frame data cleaning](https://statisticsglobe.com/wp-content/uploads/2022/04/table-11-data-frame-data-cleaning-r-programming-language.png "Table 11")

As shown in Table 11, we have created another version of our data frame where the categories “b” and “c” have been replaced by the category “a”.

## Video & Further Resources

Note that this tutorial has only shown a brief introduction to different data cleaning techniques.

I have recently released a video on my YouTube channel, which demonstrates the R programming code and the instruction text of this tutorial in some more detail. Please find the video below:

_The YouTube video will be added soon._

In addition, you might want to read the related posts to this topic on Statistics Globe.

-   [Insert Character Pattern at Particular Position of String](https://statisticsglobe.com/insert-character-pattern-in-string-r)
-   [Add Header to Data Frame in R](https://statisticsglobe.com/add-header-to-data-frame-in-r)
-   [Remove Bottom N Rows from Data Frame](https://statisticsglobe.com/remove-bottom-n-rows-from-data-frame-in-r)
-   [Only Import Selected Columns of Data in R](https://statisticsglobe.com/only-import-selected-columns-of-data-in-r)
-   [Reshape Data Frame from Long to Wide Format](https://statisticsglobe.com/reshape-data-frame-from-long-to-wide-format-in-r)
-   [Replace Specific Characters in String in R](https://statisticsglobe.com/r-replace-specific-characters-in-string)
-   [R Programming Examples](https://statisticsglobe.com/r-programming-language/)

You may also use the search icon on the top-right side of the Statistics Globe menu bar as a cheat sheet, in case you are looking for specific and more detailed advice on a certain topic step-by-step.

Furthermore, I recommend having a look at packages such as dplyr, tidyverse, and stringr. They provide additional functions and commands for the application of data cleaning techniques and are very useful when it comes to the preparation and handling of data frames.

In summary: In this tutorial you have learned how to **prepare and clean bad data frames** for survey data and other types of data sets in R. In case you have additional questions, kindly let me know in the comments below.



